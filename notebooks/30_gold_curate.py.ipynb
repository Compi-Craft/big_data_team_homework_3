{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ffd40a86-dd7c-419f-8b5b-7f77964baf6a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F\n",
    "import uuid\n",
    "\n",
    "CATALOG = \"airbnb_lab3\"\n",
    "SILVER_DB = \"airbnb_silver\"\n",
    "GOLD_DB = \"airbnb_gold\"\n",
    "\n",
    "spark.sql(f\"CREATE SCHEMA IF NOT EXISTS {CATALOG}.{GOLD_DB}\")\n",
    "def fq(db, t): return f\"{CATALOG}.{db}.{t}\"\n",
    "def city_tbl(db, base, city): return f\"{CATALOG}.{db}.{base}_{city}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c9ad714f-6129-4522-b1c2-05cb1aa93285",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def recreate_partitioned(table_fqn: str, df, partition_cols=(\"yyyymm\",)):\n",
    "    tmpv = f\"tmp_{uuid.uuid4().hex[:8]}\"\n",
    "    df.createOrReplaceTempView(tmpv)\n",
    "    spark.sql(f\"DROP TABLE IF EXISTS {table_fqn}\")\n",
    "    spark.sql(f\"\"\"\n",
    "      CREATE TABLE {table_fqn}\n",
    "      USING DELTA\n",
    "      PARTITIONED BY ({\",\".join(partition_cols)})\n",
    "      AS SELECT * FROM {tmpv}\n",
    "    \"\"\")\n",
    "    spark.catalog.dropTempView(tmpv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4f9ea0ce-d28a-4e5f-b7fb-10b42edde11c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# ---------- Monthly city metrics (incl. occupancy) ----------\n",
    "def monthly_metrics_for(city):\n",
    "    l = spark.table(city_tbl(SILVER_DB, \"silver_listings\", city)).alias(\"l\")\n",
    "    c = spark.table(city_tbl(SILVER_DB, \"silver_calendar\", city)).alias(\"c\")\n",
    "    cm = c.withColumn(\"yyyymm\", F.date_format(\"date\",\"yyyy-MM\"))\n",
    "\n",
    "    day_agg = (cm.groupBy(\"listing_id\",\"yyyymm\")\n",
    "                 .agg(F.sum(F.col(\"is_occupied\").cast(\"int\")).alias(\"occupied_days\"),\n",
    "                      F.count(F.lit(1)).alias(\"total_days\"),\n",
    "                      F.avg(\"price\").alias(\"avg_price\")))\n",
    "\n",
    "    j = (day_agg.join(l.select(\"listing_id\",\"review_scores_rating\"), \"listing_id\", \"left\")\n",
    "              .withColumn(\"city\", F.lit(city.upper()))\n",
    "              .withColumn(\n",
    "                  \"occupancy_rate\",\n",
    "                  F.when(F.col(\"total_days\") > 0, F.col(\"occupied_days\")/F.col(\"total_days\")).otherwise(F.lit(0.0))\n",
    "              )\n",
    "              .withColumn(\"occupancy_rate\", F.least(F.lit(1.0), F.greatest(F.lit(0.0), F.col(\"occupancy_rate\"))))\n",
    "         )\n",
    "\n",
    "    out = (j.groupBy(\"city\",\"yyyymm\")\n",
    "             .agg(F.countDistinct(\"listing_id\").alias(\"total_listings\"),\n",
    "                  F.avg(\"avg_price\").alias(\"avg_nightly_price\"),\n",
    "                  F.avg(\"review_scores_rating\").alias(\"avg_review_score\"),\n",
    "                  F.avg(\"occupancy_rate\").alias(\"avg_occupancy_rate\")))\n",
    "\n",
    "    # final no-NULL guarantee\n",
    "    return out.na.fill({\n",
    "        \"total_listings\": 0,\n",
    "        \"avg_nightly_price\": 0.0,\n",
    "        \"avg_review_score\": 0.0,\n",
    "        \"avg_occupancy_rate\": 0.0\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "28e51700-be16-4896-997c-2f827a9a5433",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "city_month = monthly_metrics_for(\"nyc\").unionByName(monthly_metrics_for(\"nyc\"), allowMissingColumns=True)\n",
    "recreate_partitioned(fq(GOLD_DB,\"gold_city_month_metrics\"), city_month)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d4c6025f-c604-45c4-9f2b-c7f857db8c2d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# ---------- Neighbourhood by month ----------\n",
    "def neighbourhood_metrics_for(city):\n",
    "    l = spark.table(city_tbl(SILVER_DB, \"silver_listings\", city))\n",
    "    c = spark.table(city_tbl(SILVER_DB, \"silver_calendar\", city)).withColumn(\"yyyymm\", F.date_format(\"date\",\"yyyy-MM\"))\n",
    "    dm = (c.groupBy(\"listing_id\",\"yyyymm\")\n",
    "            .agg(F.sum(F.col(\"is_occupied\").cast(\"int\")).alias(\"occupied_days\"),\n",
    "                 F.count(F.lit(1)).alias(\"total_days\"),\n",
    "                 F.avg(\"price\").alias(\"avg_price\")))\n",
    "    j = dm.join(l.select(\"listing_id\",\"neighbourhood\"), \"listing_id\", \"left\")\n",
    "    out = (j.groupBy(F.lit(city.upper()).alias(\"city\"), \"yyyymm\", \"neighbourhood\")\n",
    "            .agg(F.countDistinct(\"listing_id\").alias(\"listing_count\"),\n",
    "                 F.avg(\"avg_price\").alias(\"avg_price\"),\n",
    "                 F.avg(F.when(F.col(\"total_days\") > 0, F.col(\"occupied_days\")/F.col(\"total_days\")).otherwise(F.lit(0.0))).alias(\"avg_occupancy_rate\")))\n",
    "    return out.na.fill({\"listing_count\": 0, \"avg_price\": 0.0, \"avg_occupancy_rate\": 0.0, \"neighbourhood\": \"unknown\"})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "eee61dad-0f58-4f40-82eb-7b8e5b3ca2dc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "neigh_all = neighbourhood_metrics_for(\"nyc\").unionByName(neighbourhood_metrics_for(\"nyc\"))\n",
    "recreate_partitioned(fq(GOLD_DB,\"gold_neighbourhood_metrics\"), neigh_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "df203b7f-b069-4ea0-ae82-a532b5dbd348",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# ---------- Room type share by month (active listings) ----------\n",
    "def roomtype_share_for(city):\n",
    "    l = spark.table(city_tbl(SILVER_DB, \"silver_listings\", city))\n",
    "    c = spark.table(city_tbl(SILVER_DB, \"silver_calendar\", city)).withColumn(\"yyyymm\", F.date_format(\"date\",\"yyyy-MM\"))\n",
    "    active = c.select(\"listing_id\",\"yyyymm\").distinct().join(l.select(\"listing_id\",\"room_type\"), \"listing_id\")\n",
    "    by_rm = active.groupBy(F.lit(city.upper()).alias(\"city\"), \"yyyymm\",\"room_type\").agg(F.countDistinct(\"listing_id\").alias(\"cnt\"))\n",
    "    total = by_rm.groupBy(\"city\",\"yyyymm\").agg(F.sum(\"cnt\").alias(\"total\"))\n",
    "    joined = by_rm.join(total, [\"city\",\"yyyymm\"], \"left\")\n",
    "    out = joined.withColumn(\"share\", F.when(F.col(\"total\") > 0, F.col(\"cnt\")/F.col(\"total\")).otherwise(F.lit(0.0)))\n",
    "    return out.na.fill({\"cnt\": 0, \"total\": 0, \"share\": 0.0, \"room_type\": \"unknown\"})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2ee651a1-0ce1-4930-b440-4756cea4af2f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "roomtype_all = roomtype_share_for(\"nyc\").unionByName(roomtype_share_for(\"nyc\"))\n",
    "recreate_partitioned(fq(GOLD_DB,\"gold_roomtype_share\"), roomtype_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "55e14e59-6823-43e1-8818-d74bcf321fae",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def table_exists(db_3part: str, table_name: str) -> bool:\n",
    "    return spark.sql(f\"SHOW TABLES IN {db_3part} LIKE '{table_name}'\").count() > 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "275dcae7-502e-4f68-bbda-1dd254b5d621",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.types import StructType, StructField, StringType, LongType\n",
    "\n",
    "def reviews_monthly_for(city):\n",
    "    db = f\"{CATALOG}.{SILVER_DB}\"\n",
    "    tbl_name = f\"silver_reviews_{city}\"\n",
    "    if table_exists(db, tbl_name):\n",
    "        r = spark.table(f\"{db}.{tbl_name}\").withColumn(\"yyyymm\", F.date_format(\"review_date\",\"yyyy-MM\"))\n",
    "        return r.groupBy(F.lit(city.upper()).alias(\"city\"), \"yyyymm\").agg(F.count(\"*\").alias(\"review_count\"))\n",
    "    else:\n",
    "        empty_schema = StructType([\n",
    "            StructField(\"city\", StringType(), True),\n",
    "            StructField(\"yyyymm\", StringType(), True),\n",
    "            StructField(\"review_count\", LongType(), True),\n",
    "        ])\n",
    "        return spark.createDataFrame([], empty_schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0e86a7dc-b1c8-45a7-8d4d-32e3b747b34f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "reviews_month = reviews_monthly_for(\"nyc\").unionByName(reviews_monthly_for(\"nyc\"), allowMissingColumns=True).na.fill({\"review_count\": 0})\n",
    "recreate_partitioned(fq(GOLD_DB,\"gold_reviews_monthly\"), reviews_month)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e168248e-e01b-434f-98e7-bc12a3d20409",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# ---------- Cross-city compare (month-aligned) ----------\n",
    "g = spark.table(fq(GOLD_DB,\"gold_city_month_metrics\"))\n",
    "cross = (g.groupBy(\"yyyymm\")\n",
    "    .pivot(\"city\", [\"LA\",\"NYC\"])\n",
    "    .agg(F.first(\"total_listings\").alias(\"total_listings\"),\n",
    "         F.first(\"avg_nightly_price\").alias(\"avg_price\"),\n",
    "         F.first(\"avg_occupancy_rate\").alias(\"occ_rate\"),\n",
    "         F.first(\"avg_review_score\").alias(\"review\"))\n",
    "    .na.fill(0)\n",
    "    .withColumn(\"delta_listings\", F.col(\"LA_total_listings\")-F.col(\"NYC_total_listings\"))\n",
    "    .withColumn(\"delta_avg_price\", F.col(\"LA_avg_price\")-F.col(\"NYC_avg_price\"))\n",
    "    .withColumn(\"delta_occ_rate\", F.col(\"LA_occ_rate\")-F.col(\"NYC_occ_rate\"))\n",
    "    .withColumn(\"delta_review\", F.col(\"LA_review\")-F.col(\"NYC_review\"))\n",
    ")\n",
    "recreate_partitioned(fq(GOLD_DB,\"gold_cross_city_compare\"), cross)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "07fceaa1-41f2-487c-a7c4-71f4692ddbe5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# City month\n",
    "city_month = (\n",
    "    monthly_metrics_for(\"la\")\n",
    "    .unionByName(monthly_metrics_for(\"nyc\"), allowMissingColumns=True)\n",
    "    .na.drop(\"any\")\n",
    ")\n",
    "city_month.write.format(\"delta\").mode(\"overwrite\").saveAsTable(fq(GOLD_DB,\"gold_city_month_metrics\"))\n",
    "\n",
    "# Neighbourhood\n",
    "neigh = (\n",
    "    neighbourhood_metrics_for(\"la\")\n",
    "    .unionByName(neighbourhood_metrics_for(\"nyc\"), allowMissingColumns=True)\n",
    "    .na.drop(\"any\")\n",
    ")\n",
    "neigh.write.format(\"delta\").mode(\"overwrite\").saveAsTable(fq(GOLD_DB,\"gold_neighbourhood_metrics\"))\n",
    "\n",
    "# Room type\n",
    "room = (\n",
    "    roomtype_share_for(\"la\")\n",
    "    .unionByName(roomtype_share_for(\"nyc\"), allowMissingColumns=True)\n",
    "    .na.drop(\"any\")\n",
    ")\n",
    "room.write.format(\"delta\").mode(\"overwrite\").saveAsTable(fq(GOLD_DB,\"gold_roomtype_share\"))\n",
    "\n",
    "# Reviews\n",
    "reviews = (\n",
    "    reviews_monthly_for(\"la\")\n",
    "    .unionByName(reviews_monthly_for(\"nyc\"), allowMissingColumns=True)\n",
    "    .na.drop(\"any\")\n",
    ")\n",
    "reviews.write.format(\"delta\").mode(\"overwrite\").saveAsTable(fq(GOLD_DB,\"gold_reviews_monthly\"))\n",
    "\n",
    "# Cross-city\n",
    "g = spark.table(fq(GOLD_DB,\"gold_city_month_metrics\"))\n",
    "cross = (\n",
    "    g.groupBy(\"yyyymm\")\n",
    "     .pivot(\"city\", [\"LA\",\"NYC\"])\n",
    "     .agg(\n",
    "         F.first(\"total_listings\").alias(\"total_listings\"),\n",
    "         F.first(\"avg_nightly_price\").alias(\"avg_price\"),\n",
    "         F.first(\"avg_occupancy_rate\").alias(\"occ_rate\"),\n",
    "         F.first(\"avg_review_score\").alias(\"review\")\n",
    "     )\n",
    "     .na.drop(\"any\")\n",
    ")\n",
    "cross.write.format(\"delta\").mode(\"overwrite\").saveAsTable(fq(GOLD_DB,\"gold_cross_city_compare\"))\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "30_gold_curate.py",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
