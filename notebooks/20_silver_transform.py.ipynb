{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e99b7f46-fce9-4067-ae92-aa1220e55381",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "dbutils.widgets.text(\"city\", \"la\")\n",
    "city = dbutils.widgets.get(\"city\").lower().strip()\n",
    "assert city in {\"la\",\"nyc\"}\n",
    "\n",
    "from pyspark.sql import functions as F\n",
    "\n",
    "CATALOG = \"airbnb_lab3\"\n",
    "BRONZE_DB = \"airbnb_bronze\"\n",
    "SILVER_DB = \"airbnb_silver\"\n",
    "\n",
    "spark.sql(f\"CREATE SCHEMA IF NOT EXISTS {CATALOG}.{SILVER_DB}\")\n",
    "def fq(db, t): return f\"{CATALOG}.{db}.{t}\"\n",
    "\n",
    "def money_to_double(col):\n",
    "    return F.regexp_replace(F.regexp_replace(col, r\"^\\$\", \"\"), \",\", \"\").cast(\"double\")\n",
    "\n",
    "def table_exists(db_3part: str, table_name: str) -> bool:\n",
    "    return spark.sql(f\"SHOW TABLES IN {db_3part} LIKE '{table_name}'\").count() > 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "06e46d18-22db-4963-8fe6-c31e21d1848b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# ===================== LISTINGS -> SILVER =====================\n",
    "bronze_listings = fq(BRONZE_DB, f\"bronze_listings_{city}\")\n",
    "l = spark.table(bronze_listings)\n",
    "\n",
    "silver_listings = (\n",
    "    l.select(\n",
    "        F.col(\"id\").cast(\"long\").alias(\"listing_id\"),\n",
    "        F.col(\"host_id\").cast(\"long\").alias(\"host_id\"),\n",
    "        F.col(\"host_name\"),\n",
    "        F.coalesce(F.col(\"neighbourhood_cleansed\"), F.col(\"neighbourhood\")).alias(\"neighbourhood\"),\n",
    "        F.col(\"room_type\"),\n",
    "        money_to_double(F.col(\"price\")).alias(\"price\"),\n",
    "        F.col(\"number_of_reviews\").cast(\"int\").alias(\"number_of_reviews\"),\n",
    "        F.col(\"review_scores_rating\").cast(\"double\").alias(\"review_scores_rating\"),\n",
    "        F.col(\"latitude\").cast(\"double\").alias(\"latitude\"),\n",
    "        F.col(\"longitude\").cast(\"double\").alias(\"longitude\")\n",
    "    )\n",
    "    .withColumn(\"city\", F.lit(city.upper()))\n",
    "    .withColumn(\"room_type\", F.lower(F.trim(\"room_type\")))\n",
    "    .withColumn(\"neighbourhood\", F.lower(F.trim(\"neighbourhood\")))\n",
    ")\n",
    "\n",
    "silver_listings_tbl = fq(SILVER_DB, f\"silver_listings_{city}\")\n",
    "(silver_listings.write.format(\"delta\").mode(\"overwrite\").option(\"overwriteSchema\",\"true\").saveAsTable(silver_listings_tbl))\n",
    "\n",
    "# ===================== CALENDAR -> SILVER =====================\n",
    "bronze_calendar = fq(BRONZE_DB, f\"bronze_calendar_{city}\")\n",
    "c = spark.table(bronze_calendar)\n",
    "\n",
    "silver_calendar = (\n",
    "    c.select(\n",
    "        F.col(\"listing_id\").cast(\"long\").alias(\"listing_id\"),\n",
    "        F.to_date(\"date\").alias(\"date\"),\n",
    "        money_to_double(F.col(\"price\")).alias(\"price\"),\n",
    "        money_to_double(F.col(\"adjusted_price\")).alias(\"adjusted_price\"),\n",
    "        F.col(\"minimum_nights\").cast(\"int\").alias(\"minimum_nights\"),\n",
    "        F.col(\"maximum_nights\").cast(\"int\").alias(\"maximum_nights\"),\n",
    "        F.when(F.col(\"available\") == F.lit(\"t\"), F.lit(True))\n",
    "         .when(F.col(\"available\") == F.lit(\"f\"), F.lit(False))\n",
    "         .otherwise(F.lit(None)).alias(\"is_available\")\n",
    "    )\n",
    "    .withColumn(\"is_occupied\", F.when(F.col(\"is_available\") == F.lit(False), F.lit(True)).otherwise(F.lit(False)))\n",
    "    .withColumn(\"city\", F.lit(city.upper()))\n",
    ")\n",
    "\n",
    "silver_calendar_tbl = fq(SILVER_DB, f\"silver_calendar_{city}\")\n",
    "(silver_calendar.write.format(\"delta\").mode(\"overwrite\").option(\"overwriteSchema\",\"true\").saveAsTable(silver_calendar_tbl))\n",
    "\n",
    "# ===================== REVIEWS -> SILVER =====================\n",
    "bronze_reviews_name = f\"bronze_reviews_{city}\"\n",
    "if table_exists(f\"{CATALOG}.{BRONZE_DB}\", bronze_reviews_name):\n",
    "    r = spark.table(fq(BRONZE_DB, bronze_reviews_name))\n",
    "    silver_reviews = (\n",
    "        r.select(\n",
    "            F.col(\"listing_id\").cast(\"long\").alias(\"listing_id\"),\n",
    "            F.col(\"id\").cast(\"long\").alias(\"review_id\"),\n",
    "            F.to_date(\"date\").alias(\"review_date\"),\n",
    "            F.col(\"reviewer_id\").cast(\"long\").alias(\"reviewer_id\"),\n",
    "            F.col(\"reviewer_name\"),\n",
    "            F.col(\"comments\")\n",
    "        ).withColumn(\"city\", F.lit(city.upper()))\n",
    "    )\n",
    "    silver_reviews_tbl = fq(SILVER_DB, f\"silver_reviews_{city}\")\n",
    "    (silver_reviews.write.format(\"delta\").mode(\"overwrite\").option(\"overwriteSchema\",\"true\").saveAsTable(silver_reviews_tbl))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9dae8e8e-e5ca-49cc-84c2-274f40124f32",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "print(f\"[SILVER âœ…] {city.upper()} written:\\n  {silver_listings_tbl}\\n  {silver_calendar_tbl}\" + (f\"\\n  {silver_reviews_tbl}\" if table_exists(f'{CATALOG}.{SILVER_DB}', f'silver_reviews_{city}') else \"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "da7f4d6c-8254-4c5e-9f54-8679ee38ebe0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "spark.sql(\"SHOW TABLES IN airbnb_lab3.airbnb_silver\").show()\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "20_silver_transform.py",
   "widgets": {
    "city": {
     "currentValue": "nyc",
     "nuid": "764e6b1d-b149-4723-a5aa-8f2716cf6ed7",
     "typedWidgetInfo": {
      "autoCreated": false,
      "defaultValue": "la",
      "label": null,
      "name": "city",
      "options": {
       "widgetDisplayType": "Text",
       "validationRegex": null
      },
      "parameterDataType": "String"
     },
     "widgetInfo": {
      "widgetType": "text",
      "defaultValue": "la",
      "label": null,
      "name": "city",
      "options": {
       "widgetType": "text",
       "autoCreated": null,
       "validationRegex": null
      }
     }
    }
   }
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
